{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_Infrared_photo_enhancer",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "oT38MEX0LAYE",
        "foad43bXLLIZ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpwUbu8KqIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7eZs3r-uCuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import tensorview as tv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM3dm0_HLaki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFnBODrVKr7v",
        "colab_type": "text"
      },
      "source": [
        "# TEST DATASET 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEaAIB6pAY06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://robotics.ethz.ch/~asl-datasets/flir_17_Sept_2013/asl_eth_flir.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtQRWXNKAjB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip asl_eth_flir.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpWTbNubAsx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob,os\n",
        "img_dir = \"flir_17_Sept_2013/Sempach-10/8bit\" \n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files = glob.glob(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBl8nSUuBC-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cqcKUEtFaRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(cv2.imread(files[200]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxQqiahvbHEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_lr = []\n",
        "test_data_hr = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxVzF25GB1Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in files:\n",
        "  im = cv2.imread(f)\n",
        "  try:\n",
        "    img_1 = tf.image.resize_with_crop_or_pad(im,256,256)\n",
        "    img_2 = tf.image.random_contrast(img_1,0.2,0.21) \n",
        "    plt.imshow(img_1)\n",
        "    plt.show()\n",
        "    plt.imshow(img_2)\n",
        "    plt.show()   \n",
        "    test_data_lr.append(np.asarray(img_2))\n",
        "    test_data_hr.append(np.asarray(img_1))\n",
        "  except:\n",
        "    print('image cannot be displayed')   \n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxT0kSblJ-7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asarray(test_data_hr).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ-EHyAxJ_Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvrXRUK-KyzL",
        "colab_type": "text"
      },
      "source": [
        "# TRAIN DATASET 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bbl687XghGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQN75L0gnbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip val2017.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnzPPdEHgtxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob,os\n",
        "img_dir = \"val2017\" \n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files2 = glob.glob(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2kPzLnRhA5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(files2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQshRFbK4_t",
        "colab_type": "text"
      },
      "source": [
        "# DATASET PART 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYIbIUlCmCjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = []\n",
        "data = []\n",
        "def crop_img(img):\n",
        "  img_1 = tf.image.random_crop(img,size=[256,256,3],seed = 90)\n",
        "  img_2 = tf.image.random_contrast(img_1,0.2,0.21)\n",
        "  img_1 = tf.image.rgb_to_grayscale(img_1)\n",
        "  img_2 = tf.image.rgb_to_grayscale(img_2)\n",
        "  img_1 = tf.concat([img_1,img_1,img_1],axis = -1)\n",
        "  img_2 = tf.concat([img_2,img_2,img_2],axis = -1)\n",
        "  return img_1,img_2\n",
        "for i in range(300):\n",
        "  try:\n",
        "    im = cv2.imread(files2[i])\n",
        "    for i in range(10):\n",
        "      im2,im3 = crop_img(im)\n",
        "   \n",
        "      target_img = im2\n",
        "      input_img = im3\n",
        "      data.append(np.asarray(target_img))\n",
        "      data2.append(np.asarray(input_img))    \n",
        "  except:\n",
        "    print('Cannot work on the image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efjBBslJemAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asarray(data2).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnZ2W04DK7ic",
        "colab_type": "text"
      },
      "source": [
        "#DATASET PART 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yQB4gePAO9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2_2 = []\n",
        "data_2 = []\n",
        "def crop_img(img):\n",
        "  img_1 = tf.image.random_crop(img,size=[256,256,3],seed = 90)\n",
        "  img_2 = tf.image.random_contrast(img_1,0.2,0.21)\n",
        "  img_1 = tf.image.rgb_to_grayscale(img_1)\n",
        "  img_2 = tf.image.rgb_to_grayscale(img_2)\n",
        "  img_1 = tf.concat([img_1,img_1,img_1],axis = -1)\n",
        "  img_2 = tf.concat([img_2,img_2,img_2],axis = -1)\n",
        "  return img_1,img_2\n",
        "for i in range(300,900):\n",
        "  try:\n",
        "    im = cv2.imread(files2[i])\n",
        "    for i in range(5):\n",
        "      im2,im3 = crop_img(im)\n",
        "      target_img = im2\n",
        "      input_img = im3\n",
        "      data_2.append(np.asarray(target_img))\n",
        "      data2_2.append(np.asarray(input_img))    \n",
        "  except:\n",
        "    print('Cannot work on the image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTFuQY1FYz18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asarray(data_2).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acZt4SaR_aS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.asarray(data2_2).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzVS4p4tY0ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fUfyNfeY1DD",
        "colab_type": "text"
      },
      "source": [
        "#DATASET PART 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGhhLqVnY3zE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2_3 = []\n",
        "data_3 = []\n",
        "def crop_img(img):\n",
        "  img_1 = tf.image.random_crop(img,size=[256,256,3],seed = 90)\n",
        "  img_2 = tf.image.random_contrast(img_1,0.2,0.21)\n",
        "  img_1 = tf.image.rgb_to_grayscale(img_1)\n",
        "  img_2 = tf.image.rgb_to_grayscale(img_2)\n",
        "  img_1 = tf.concat([img_1,img_1,img_1],axis = -1)\n",
        "  img_2 = tf.concat([img_2,img_2,img_2],axis = -1)\n",
        "  return img_1,img_2\n",
        "for i in range(900,1500):\n",
        "  try:\n",
        "    im = cv2.imread(files2[i])\n",
        "    for i in range(5):\n",
        "      im2,im3 = crop_img(im)\n",
        "      target_img = im2\n",
        "      input_img = im3\n",
        "      data_3.append(np.asarray(target_img))\n",
        "      data2_3.append(np.asarray(input_img))    \n",
        "  except:\n",
        "    print('Cannot work on the image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25ijo7DIqara",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asarray(data_3).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hChqf1VojUwd",
        "colab_type": "text"
      },
      "source": [
        "# DATASET PART 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er2tUCT_jXPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2_4 = []\n",
        "data_4 = []\n",
        "def crop_img(img):\n",
        "  img_1 = tf.image.random_crop(img,size=[256,256,3],seed = 90)\n",
        "  img_2 = tf.image.random_contrast(img_1,0.2,0.21)\n",
        "  img_1 = tf.image.rgb_to_grayscale(img_1)\n",
        "  img_2 = tf.image.rgb_to_grayscale(img_2)\n",
        "  img_1 = tf.concat([img_1,img_1,img_1],axis = -1)\n",
        "  img_2 = tf.concat([img_2,img_2,img_2],axis = -1)\n",
        "  return img_1,img_2\n",
        "for i in range(1500,2100):\n",
        "  try:\n",
        "    im = cv2.imread(files2[i])\n",
        "    for i in range(5):\n",
        "      im2,im3 = crop_img(im)\n",
        "      target_img = im2\n",
        "      input_img = im3\n",
        "      data_4.append(np.asarray(target_img))\n",
        "      data2_4.append(np.asarray(input_img))    \n",
        "  except:\n",
        "    print('Cannot work on the image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMDKfaoK04L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNRjPgz904g9",
        "colab_type": "text"
      },
      "source": [
        "#DATASET PART 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yKYzpZnwBrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2_5 = []\n",
        "data_5 = []\n",
        "def crop_img(img):\n",
        "  img_1 = tf.image.random_crop(img,size=[256,256,3],seed = 90)\n",
        "  img_2 = tf.image.random_contrast(img_1,0.2,0.21)\n",
        "  img_1 = tf.image.rgb_to_grayscale(img_1)\n",
        "  img_2 = tf.image.rgb_to_grayscale(img_2)\n",
        "  img_1 = tf.concat([img_1,img_1,img_1],axis = -1)\n",
        "  img_2 = tf.concat([img_2,img_2,img_2],axis = -1)\n",
        "  return img_1,img_2\n",
        "for i in range(2100,2700):\n",
        "  try:\n",
        "    im = cv2.imread(files2[i])\n",
        "    for i in range(5):\n",
        "      im2,im3 = crop_img(im)\n",
        "  \n",
        "      target_img = im2\n",
        "      input_img = im3\n",
        "      data_5.append(np.asarray(target_img))\n",
        "      data2_5.append(np.asarray(input_img))    \n",
        "  except:\n",
        "    print('Cannot work on the image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XssalXlB08Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj54ww-Z08SP",
        "colab_type": "text"
      },
      "source": [
        "#DATASET PART 6\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et4igCWW1FAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2_6 = []\n",
        "data_6 = []\n",
        "def crop_img(img):\n",
        "  img_1 = tf.image.random_crop(img,size=[256,256,3],seed = 90)\n",
        "  img_2 = tf.image.random_contrast(img_1,0.2,0.21)\n",
        "  img_1 = tf.image.rgb_to_grayscale(img_1)\n",
        "  img_2 = tf.image.rgb_to_grayscale(img_2)\n",
        "  img_1 = tf.concat([img_1,img_1,img_1],axis = -1)\n",
        "  img_2 = tf.concat([img_2,img_2,img_2],axis = -1)\n",
        "  return img_1,img_2\n",
        "for i in range(2700,3300):\n",
        "  try:\n",
        "    im = cv2.imread(files2[i])\n",
        "    for i in range(5):\n",
        "      im2,im3 = crop_img(im)\n",
        "     \n",
        "      target_img = im2\n",
        "      input_img = im3\n",
        "      data_6.append(np.asarray(target_img))\n",
        "      data2_6.append(np.asarray(input_img))    \n",
        "  except:\n",
        "    print('Cannot work on the image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKs46nGY06Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asarray(data_6).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMkLB07FEfPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2.extend(data2_2)\n",
        "data.extend(data_2)\n",
        "data2.extend(data2_3)\n",
        "data.extend(data_3)\n",
        "data2.extend(data2_4)\n",
        "data.extend(data_4)\n",
        "data2.extend(data2_5)\n",
        "data.extend(data_5)\n",
        "data2.extend(data2_6)\n",
        "data.extend(data_6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPw6DXjdhY-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_array = np.asarray(data)\n",
        "np.savez_compressed(\"data.npz\",data_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN7a8z74YR1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2_array = np.asarray(data2)\n",
        "np.savez_compressed(\"data2.npz\",data2_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN2FKzdPcRkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_array = np.load(\"data.npz\")\n",
        "data2_array = np.load(\"data2.npz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOjIlkkUtZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sub(filters = 64):\n",
        "  input_img = tf.keras.Input(shape=(256,256,3))\n",
        "  input_image = tf.keras.layers.Conv2D(filters=64,kernel_size=(4,4),strides=2,padding = 'same')(input_img)\n",
        "  c1 = tf.keras.layers.ReLU()(input_image)\n",
        "  p1 = c1\n",
        "  c1 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c1)\n",
        "  c1 = tf.keras.layers.BatchNormalization()(c1)\n",
        "  c2 = tf.keras.layers.ReLU()(c1)\n",
        "  c2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c2)\n",
        "  c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "  c3 = tf.keras.layers.ReLU()(c2)  \n",
        "  u1 = tf.concat([c3,p1],axis = -1)\n",
        "  u2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(1,1),strides=1)(u1)\n",
        "  u3 = tf.keras.layers.Conv2DTranspose(filters = 3,kernel_size=(4,4),strides = 2,padding = 'same')(u2)\n",
        "  u4 = tf.keras.activations.tanh(u3)\n",
        "  gen_sub = tf.keras.Model(input_img,u4)\n",
        "  return gen_sub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ddEXnNP1L5W",
        "colab_type": "text"
      },
      "source": [
        "Other generator configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dyoz8g_O6Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sub_2(filters = 64):\n",
        "  input_img = tf.keras.Input(shape=(256,256,3))\n",
        "  input_image = tf.keras.layers.Conv2D(filters=64,kernel_size=(4,4),strides=2,padding='same')(input_img)\n",
        "  c1 = tf.keras.layers.ReLU()(input_image)\n",
        "  p1 = c1\n",
        "  c1 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c1)\n",
        "  c1 = tf.keras.layers.BatchNormalization()(c1)\n",
        "  c2 = tf.keras.layers.ReLU()(c1)\n",
        "  c2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c2)\n",
        "  c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "  c3 = tf.keras.layers.ReLU()(c2) \n",
        "  u1 = tf.concat([c3,p1],axis = -1)\n",
        "  p2 = u1\n",
        "  c3 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(u1)\n",
        "  c3 = tf.keras.layers.BatchNormalization()(c3)\n",
        "  c4 = tf.keras.layers.ReLU()(c1)\n",
        "  c4 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c4)\n",
        "  c4 = tf.keras.layers.BatchNormalization()(c4)\n",
        "  c5 = tf.keras.layers.ReLU()(c4)  \n",
        "  \n",
        "  u2 = tf.concat([c5,p2],axis = -1)\n",
        "  u2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(1,1),strides=1)(u2)\n",
        "  u3 = tf.keras.layers.Conv2DTranspose(filters = 3,kernel_size=(4,4),strides = 2,padding = 'same')(u2)\n",
        "  u4 = tf.keras.activations.tanh(u3)\n",
        "  gen_sub = tf.keras.Model(input_img,u4)\n",
        "  return gen_sub\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC73NowpWKBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sub_3(filters = 64):\n",
        "  input_img = tf.keras.Input(shape=(256,256,3))\n",
        "  input_image = tf.keras.layers.Conv2D(filters=64,kernel_size=(4,4),strides=2,padding='same')(input_img)\n",
        "  c1 = tf.keras.layers.ReLU()(input_image)\n",
        "  p1 = c1\n",
        "  c1 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c1)\n",
        "  c1 = tf.keras.layers.BatchNormalization()(c1)\n",
        "  c2 = tf.keras.layers.ReLU()(c1)\n",
        "  c2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c2)\n",
        "  c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "  c3 = tf.keras.layers.ReLU()(c2) \n",
        "  c3 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c3)\n",
        "  c3 = tf.keras.layers.BatchNormalization()(c3)\n",
        "  c4 = tf.keras.layers.ReLU()(c1)\n",
        "  c4 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c4)\n",
        "  c4 = tf.keras.layers.BatchNormalization()(c4)\n",
        "  c5 = tf.keras.layers.ReLU()(c4)  \n",
        "  u1 = tf.concat([c5,p1],axis = -1)\n",
        "  u2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(1,1),strides=1)(u1)\n",
        "  u3 = tf.keras.layers.Conv2DTranspose(filters = 3,kernel_size=(4,4),strides = 2,padding = 'same')(u2)\n",
        "  u4 = tf.keras.activations.tanh(u3)\n",
        "  gen_sub = tf.keras.Model(input_img,u4)\n",
        "  return gen_sub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Aa0WiRWXAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sub_4(filters = 64):\n",
        "  input_img = tf.keras.Input(shape=(256,256,3))\n",
        "  input_image = tf.keras.layers.Conv2D(filters=64,kernel_size=(4,4),strides=2,padding='same')(input_img)\n",
        "  c1 = tf.keras.layers.ReLU()(input_image)\n",
        "  p1 = c1\n",
        "  c1 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c1)\n",
        "  c1 = tf.keras.layers.BatchNormalization()(c1)\n",
        "  c2 = tf.keras.layers.ReLU()(c1)\n",
        "  p2 = c2\n",
        "  c2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c2)\n",
        "  c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "  c3 = tf.keras.layers.ReLU()(c2) \n",
        "  c3 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c3)\n",
        "  c3 = tf.keras.layers.BatchNormalization()(c3)\n",
        "  c4 = tf.keras.layers.ReLU()(c1)\n",
        "  u1 = tf.concat([c4,p2],axis = -1)\n",
        "  c4 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(u1)\n",
        "  c4 = tf.keras.layers.BatchNormalization()(c4)\n",
        "  c5 = tf.keras.layers.ReLU()(c4)  \n",
        "  u2 = tf.concat([c5,p1],axis = -1)\n",
        "  u2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(1,1),strides=1)(u2)\n",
        "  u3 = tf.keras.layers.Conv2DTranspose(filters = 3,kernel_size=(4,4),strides = 2,padding = 'same')(u2)\n",
        "  u4 = tf.keras.activations.tanh(u3)\n",
        "  gen_sub = tf.keras.Model(input_img,u4)\n",
        "  return gen_sub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8h-9vyFZLGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD54M_5Nxkl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return -tf.math.reduce_mean(y_true * y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcgR4ZY1gtDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def disc_sub(filters = 64):\n",
        "  input_img = tf.keras.Input(shape = (256,256,6))\n",
        "  c1 = tf.keras.layers.Conv2D(filters = filters,kernel_size=(4,4),strides=2,padding='same')(input_img)\n",
        "  c2 = tf.keras.layers.LeakyReLU()(c1)\n",
        "  c2 = tf.keras.layers.Conv2D(filters = filters*2,kernel_size=(4,4),strides=2,padding='same')(c2)\n",
        "  c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "  c3 = tf.keras.layers.LeakyReLU()(c2)\n",
        "  c3 = tf.keras.layers.Conv2D(filters = filters*4,kernel_size=(4,4),strides=2,padding='same')(c3)\n",
        "  c3 = tf.keras.layers.BatchNormalization()(c3)\n",
        "  c4 = tf.keras.layers.LeakyReLU()(c3)\n",
        "  c4 = tf.keras.layers.Conv2D(filters = filters*8,kernel_size=(4,4),strides=1,padding='same')(c4)\n",
        "  c4 = tf.keras.layers.BatchNormalization()(c4)\n",
        "  c5 = tf.keras.layers.LeakyReLU()(c4) \n",
        "  c6 = tf.keras.layers.Conv2D(filters = 1,kernel_size=(4,4),strides=1,padding='same')(c5)\n",
        "  c7 = tf.keras.activations.sigmoid(c6)\n",
        "  disc = tf.keras.Model(input_img,c7)\n",
        "  return disc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYWoTPWm7EQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc_sub = disc_sub()\n",
        "disc_sub.compile(loss=wasserstein_loss,optimizer=tf.keras.optimizers.Adam(learning_rate=0.2,beta_1 = 0.5),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs9uReOgfCpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genet = gen_sub()\n",
        "frozen = tf.keras.Model(disc_sub.inputs, disc_sub.outputs)\n",
        "frozen.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBK5860CfqgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "noise = tf.keras.Input(shape=(256,256,3))\n",
        "image = genet(noise)\n",
        "inp_ = tf.concat([noise,image],axis = -1)\n",
        "logit = frozen(inp_)\n",
        "wgan = tf.keras.Model(noise, logit)\n",
        "wgan.compile(loss=wasserstein_loss,optimizer=tf.keras.optimizers.Adam(learning_rate=0.2,beta_1 = 0.5),metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stXhiTK65L5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_x = np.asarray(data_array[\"arr_0\"])\n",
        "data_y = np.asarray(data2_array[\"arr_0\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5N3QNRiUfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = data_x[:16384]\n",
        "y_train = data_y[:16384]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33YWg7dP_0Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvMmDSaH2C07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tv_plot = tv.train.PlotMetrics(columns=2, wait_num=5)\n",
        "batch_size = 32\n",
        "n_critic = x_train.shape[0]//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgeuHNNkhe5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_critic = x_train.shape[0]//batch_size\n",
        "clip_value = 0.01\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  for i in range(n_critic):\n",
        "    batch_image = x_train[i*batch_size:(i+1)*batch_size]\n",
        "    batch_noise = y_train[i*batch_size:(i+1)*batch_size]\n",
        "    batch_gen_image = genet.predict(batch_noise)\n",
        "\n",
        "    image_noise = np.concatenate((batch_image,batch_noise),axis =-1)\n",
        "    gen_noise = np.concatenate((batch_gen_image,batch_noise),axis =-1)\n",
        "\n",
        "    d_loss_real = disc_sub.train_on_batch(image_noise,np.ones((batch_size,1)))\n",
        "    d_loss_fake = disc_sub.train_on_batch(gen_noise,np.zeros((batch_size,1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real,d_loss_fake)\n",
        "    for l in disc_sub.layers:\n",
        "      weights = l.get_weights()\n",
        "      weights = [np.clip(w,-clip_value,clip_value) for w in weights]\n",
        "      l.set_weights(weights)\n",
        "    disc_sub.trainable = False\n",
        "    g_loss = wgan.train_on_batch(batch_noise,-np.ones((batch_size,1)))\n",
        "    disc_sub.trainable = True\n",
        "    genet.save_weights(\"gen_sub\",True)\n",
        "    disc_sub.save_weights(\"disc_sub\",True)\n",
        "    tv_plot.update({'D_loss':d_loss[0],'G_loss':g_loss[0]})\n",
        "  print(\"epoch {} and loss {} \".format(epoch,g_loss[0]))\n",
        " \n",
        "  tv_plot.draw()\n",
        "tv_plot.visual()\n",
        "tv_plot.visual(name = 'model_visual_gif',gif = True)      \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeR62l9vO6SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlyRC67DqNRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT38MEX0LAYE",
        "colab_type": "text"
      },
      "source": [
        "#PSNR TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRz4OD4F0ZXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def compute_psnr(img1, img2):\n",
        "  img1 = img1.astype(np.float64) / 255.\n",
        "  img2 = img2.astype(np.float64) / 255.\n",
        "  mse = np.mean((img1 - img2) ** 2)\n",
        "  if mse == 0:\n",
        "    return \"Same Image\"\n",
        "  return 10 * math.log10(1. / mse)\n",
        "def psnr_test(test_LR,test_HR):\n",
        "  image_ = test_LR\n",
        "  image_gen_ = genet.predict(image_)\n",
        "  \n",
        "  psnr_result = compute_psnr(np.asarray(image_gen_),test_HR)\n",
        "  return psnr_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtpiX2R9GvVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "psnr_test(np.asarray(test_data_lr[:64]),np.asarray(test_data_hr[:64]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2UFya8vILi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}